{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Hz9rXJHZDZeEY4pbWkLYFhZftVekADdY",
      "authorship_tag": "ABX9TyNxZxazCThzqenbaDmXugWd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2023-nlp/blob/main/12_evaluate_text_similarity_with_language_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t-iVvqcVnB5"
      },
      "source": [
        "# 言語モデルを用いたテキストの類似度評価\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im8djYmZkB3b"
      },
      "source": [
        "* 今回は、3種類の言語モデルを使ってテキストをembedする。\n",
        "* その後、コサイン類似度でテキスト間の類似度を求める。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ランタイムのタイプはGPUに設定しておく。**"
      ],
      "metadata": {
        "id": "itAjMkKFwUev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## インストール"
      ],
      "metadata": {
        "id": "AfX3eDm2BmAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 今回は、軽量なモデルはSentence Transformersライブラリから使うことにする。\n",
        "  * https://www.sbert.net/\n",
        "* `fugashi[unidic-lite]`はcl-tohoku/bert-base-japanese-v3を使うために必要。\n",
        "* `auto-gptq`は量子化されたモデルを使うために必要。\n",
        "  * https://huggingface.co/blog/gptq-integration"
      ],
      "metadata": {
        "id": "SM-EdTK1l9sC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6V_dyqv0n1o"
      },
      "source": [
        "!pip install fugashi[unidic-lite] sentence-transformers accelerate datasets auto-gptq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "\n",
        "def set_seed(seed: int):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(123)"
      ],
      "metadata": {
        "id": "PHhVhI4thpkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット\n",
        "* 今回は、Hugging Face Hubから、ライブドア・ニュースコーパスを取得する。\n",
        "  * `random_state`を指定して、ランダムにtrain/validation/test setsへ8:1:1の割合で初めから分割しておく。"
      ],
      "metadata": {
        "id": "IyOHv6Vpde75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\n",
        "    \"shunk031/livedoor-news-corpus\",\n",
        "    train_ratio=0.8,\n",
        "    val_ratio=0.1,\n",
        "    test_ratio=0.1,\n",
        "    random_state=42, # 再現性の確保\n",
        "    shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "id": "eaiYx2_ndSV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][\"title\"][:10]"
      ],
      "metadata": {
        "id": "zh7wI8rKfGMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 記事のカテゴリをPyTorchのテンソルに変換しておく。"
      ],
      "metadata": {
        "id": "-ap0iq-bsTI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.keys()"
      ],
      "metadata": {
        "id": "yaTBj_ZAhhaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category = {}\n",
        "for key in dataset.keys():\n",
        "  category[key] = torch.tensor(dataset[key][\"category\"])"
      ],
      "metadata": {
        "id": "RwMQj6FnntGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(category[\"train\"])"
      ],
      "metadata": {
        "id": "0mAH3lvUSWfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (A) cl-tohoku/bert-base-japanese-v3"
      ],
      "metadata": {
        "id": "I3RGWUNzBoo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* このモデルについては、下記を参照。\n",
        "  * https://huggingface.co/cl-tohoku/bert-base-japanese-v3"
      ],
      "metadata": {
        "id": "cz0DjQL0zvaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `sentence_transformers`ライブラリを使って、モデルをダウンロードする。\n",
        "  * `cl-tohoku/bert-base-japanese-v3`は、embedding向けにfinetuningはされていない。"
      ],
      "metadata": {
        "id": "VH1iTWRqzjFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"cl-tohoku/bert-base-japanese-v3\")"
      ],
      "metadata": {
        "id": "P1yDjdhl4rid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 簡単なテキストをembedしてみる。"
      ],
      "metadata": {
        "id": "6cRGusJkB32F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"これはりんごです。\",\n",
        "    \"これはりんごですか？\",\n",
        "    \"あれはりんごです。\",\n",
        "]"
      ],
      "metadata": {
        "id": "IPWVoDjfrRj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LalaUJ22k9dU"
      },
      "source": [
        "embeddings = model.encode(corpus, convert_to_tensor=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_embeddings = F.normalize(embeddings, dim=-1)"
      ],
      "metadata": {
        "id": "8tv1E390kecM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_embeddings @ normalized_embeddings.t()"
      ],
      "metadata": {
        "id": "SAshltgVl01U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ライブドア・ニュースコーパスのタイトルをすべてembedする。\n",
        "  * 15秒ぐらいで終わる。"
      ],
      "metadata": {
        "id": "KeugJKwffnGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_bert = {}\n",
        "for key in dataset.keys():\n",
        "  embeddings_bert[key] = model.encode(dataset[key][\"title\"], convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "sdcpxUWefNjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* embeddingの次元を確認する。"
      ],
      "metadata": {
        "id": "4JE_o4LNS42v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_bert[\"train\"].shape"
      ],
      "metadata": {
        "id": "VJAefnW_fUq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* validation setとtraining setとのすべてのペアで類似度を計算する。"
      ],
      "metadata": {
        "id": "oURhANuQr0FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = torch.matmul(\n",
        "    F.normalize(embeddings_bert[\"validation\"], dim=-1),\n",
        "    F.normalize(embeddings_bert[\"train\"], dim=-1).t()\n",
        ")"
      ],
      "metadata": {
        "id": "ddzMhaimhcAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities.shape"
      ],
      "metadata": {
        "id": "UdB7-tEyf06-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_indices = torch.argsort(similarities, descending=True).cpu()"
      ],
      "metadata": {
        "id": "G6SX1PFdnT_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_indices.shape"
      ],
      "metadata": {
        "id": "u-jt9Xc2njSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* validation setのテキスト0について、上位テキストのカテゴリを確認する。"
      ],
      "metadata": {
        "id": "qFFg-_VGsAez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category[\"train\"][sorted_indices[0,:20]]"
      ],
      "metadata": {
        "id": "IPr55a5en9QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category[\"validation\"][0]"
      ],
      "metadata": {
        "id": "HSE6_cAboIu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 最も近いテキストのカテゴリが、正解カテゴリに一致するかで評価してみる。"
      ],
      "metadata": {
        "id": "tGmGV-RqtEBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(category[\"train\"][sorted_indices[:,0]] == category[\"validation\"]).sum() / len(category[\"validation\"])"
      ],
      "metadata": {
        "id": "B34QI4Ffs_pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (B) intfloat/multilingual-e5-small\n",
        "* E5というモデルについては、下記を参照。\n",
        "  * https://huggingface.co/intfloat/multilingual-e5-base\n",
        "  * https://hironsan.hatenablog.com/entry/2023/07/05/073150"
      ],
      "metadata": {
        "id": "DBNHm23Ex5hE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* このモデルは、テキストのembedding向けにすでにfinetuningされている。"
      ],
      "metadata": {
        "id": "QFDNU2WezoTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"intfloat/multilingual-e5-base\")"
      ],
      "metadata": {
        "id": "PFTP7UAWg_8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_embeddings = F.normalize(model.encode(corpus, convert_to_tensor=True), dim=-1)\n",
        "normalized_embeddings @ normalized_embeddings.t()"
      ],
      "metadata": {
        "id": "m8ZnMj55pUAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_e5 = {}\n",
        "for key in dataset.keys():\n",
        "  embeddings_e5[key] = model.encode(dataset[key][\"title\"], convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "-TQipqeQhRtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = torch.matmul(\n",
        "    F.normalize(embeddings_e5[\"validation\"], dim=-1),\n",
        "    F.normalize(embeddings_e5[\"train\"], dim=-1).t()\n",
        ")"
      ],
      "metadata": {
        "id": "wqL0iFZyorLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_indices = torch.argsort(similarities, descending=True).cpu()"
      ],
      "metadata": {
        "id": "ETkC_1TbsfwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(category[\"validation\"][2], category[\"train\"][sorted_indices[2,:20]])"
      ],
      "metadata": {
        "id": "PafMDF34o37k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(category[\"train\"][sorted_indices[:,0]] == category[\"validation\"]).sum() / len(category[\"validation\"])"
      ],
      "metadata": {
        "id": "RE3LbtFww85M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (C) dahara1/weblab-10b-instruction-sft-GPTQ\n",
        "* https://huggingface.co/dahara1/weblab-10b-instruction-sft-GPTQ"
      ],
      "metadata": {
        "id": "OuIhY1jZ-nTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `matsuo-lab/weblab-10b-instruction-sft`をAutoGPTQで量子化したモデル。\n",
        "  * https://huggingface.co/matsuo-lab/weblab-10b-instruction-sft"
      ],
      "metadata": {
        "id": "DgK3mRMN1NiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model_dir = \"dahara1/weblab-10b-instruction-sft-GPTQ\"\n",
        "model_basename = \"gptq_model-4bit-128g\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(quantized_model_dir)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "  quantized_model_dir,\n",
        "  model_basename=model_basename,\n",
        "  use_safetensors=True,\n",
        "  device=\"cuda:0\",\n",
        "  )"
      ],
      "metadata": {
        "id": "jR9TXobPm67T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_dict = tokenizer(corpus, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
        "with torch.no_grad():\n",
        "  outputs = model(\n",
        "    input_ids=batch_dict.input_ids,\n",
        "    attention_mask=batch_dict.attention_mask,\n",
        "    output_hidden_states=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "gFxScAIIn4qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_pool(last_hidden_states, attention_mask):\n",
        "  last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "  return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
      ],
      "metadata": {
        "id": "CgxMlX7Ky4-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* modelのoutputの詳細は、下記を参照。\n",
        "  * https://huggingface.co/docs/transformers/main_classes/output"
      ],
      "metadata": {
        "id": "IKl4XMXaWQtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "id": "bnHrahEEp7F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = average_pool(outputs.hidden_states[-1], batch_dict.attention_mask).cpu()"
      ],
      "metadata": {
        "id": "NMoM8_sdrO7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embeddings.type(torch.float32)\n",
        "normalized_embeddings = F.normalize(embeddings, dim=-1)\n",
        "normalized_embeddings @ normalized_embeddings.t()"
      ],
      "metadata": {
        "id": "eXkkyLT6r1o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 11分ぐらいかかる。"
      ],
      "metadata": {
        "id": "Mtw2uMSLZCJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "embeddings_list = {}\n",
        "for key in dataset.keys():\n",
        "  corpus = dataset[key][\"title\"]\n",
        "  offset = 0\n",
        "  embeddings_list[key] = list()\n",
        "  for offset in tqdm_notebook(range(0, len(corpus), batch_size)):\n",
        "    batch_dict = tokenizer(\n",
        "        corpus[offset:offset+batch_size],\n",
        "        padding=True, truncation=True, return_tensors='pt'\n",
        "        ).to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "      last_hidden_state = model(\n",
        "          input_ids=batch_dict.input_ids,\n",
        "          attention_mask=batch_dict.attention_mask,\n",
        "          output_hidden_states=True,\n",
        "          ).hidden_states[-1].cpu()\n",
        "    tmp_embeddings = average_pool(last_hidden_state, batch_dict.attention_mask.cpu())\n",
        "    embeddings_list[key].append(tmp_embeddings)\n",
        "    offset += batch_size"
      ],
      "metadata": {
        "id": "w3XjRoNTweV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_weblab = {}\n",
        "for key in dataset.keys():\n",
        "  embeddings_weblab[key] = torch.concat(embeddings_list[key]).type(torch.float32)\n",
        "  print(key, embeddings_weblab[key].shape)"
      ],
      "metadata": {
        "id": "fknvdTnVw6BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in dataset.keys():\n",
        "  torch.save(embeddings_weblab[key], f\"livedoor_weblab-10b-instruction-sft-GPTQ_{key}.pt\")"
      ],
      "metadata": {
        "id": "4L-BnsoS9xDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = torch.matmul(\n",
        "    F.normalize(embeddings_weblab[\"validation\"], dim=-1),\n",
        "    F.normalize(embeddings_weblab[\"train\"], dim=-1).t()\n",
        ")"
      ],
      "metadata": {
        "id": "SW9OCbPv9Pa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_indices = torch.argsort(similarities, descending=True).cpu()"
      ],
      "metadata": {
        "id": "pwYrC6M3wcfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(category[\"validation\"][0], category[\"train\"][sorted_indices[0,:20]])"
      ],
      "metadata": {
        "id": "_PK0LgR5wc9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(category[\"train\"][sorted_indices[:,0]] == category[\"validation\"]).sum() / len(category[\"validation\"])"
      ],
      "metadata": {
        "id": "_s5yzB2nswXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題\n",
        "* 最低限、上のコードをすべて動かそう。\n",
        "* 余裕がある人は、validation setのテキストのカテゴリを、上のように1-NNではなく、k>1のk-NNで予測すると予測性能が上がるかどうか、調べてみよう。"
      ],
      "metadata": {
        "id": "FfJyQ_L-xSJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hM-WyRMYxfaT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}