{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Ju5Lc6g45t9qjI0R2cFUAA1wHBFm2IeB",
      "authorship_tag": "ABX9TyOcTr7UvIqPODgSclky0mDB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2023-nlp/blob/main/07_PyTorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hx2zN0IvyqF"
      },
      "source": [
        "# PyTorch入門 (3)\n",
        "* チュートリアルをほぼそのまま使う。\n",
        " * https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        "* テキスト分類をPyTorchで実装する。\n",
        "* torchtextの使い方も併せて学ぶ。\n",
        " * https://pytorch.org/text/stable/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備"
      ],
      "metadata": {
        "id": "iIHq0CF9oMqf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAv8yYt8-Yn0"
      },
      "source": [
        "* ランタイムの設定でGPUを選択しておこう。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* torchdataを使うために必要なパッケージのインストール"
      ],
      "metadata": {
        "id": "_esbFOZ9pZso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbjXLZStpYp9",
        "outputId": "2c31577f-0c2e-4963-cc1e-c85d6b368570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ここでランタイムを再起動すること。**"
      ],
      "metadata": {
        "id": "SH9zA1e_qC-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorchのインポート"
      ],
      "metadata": {
        "id": "_0jLWNWjk1DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 再現性の確保\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# 使用するデバイスの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "EecUGZKspEal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torchtext.datasets`"
      ],
      "metadata": {
        "id": "7MU1kOIZpGuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* torchtextに準備された仕組みを利用して、データセットを準備する。\n",
        "* 今回はAG_NEWSというテキスト分類用のデータセットを使う。"
      ],
      "metadata": {
        "id": "PvExI-tmpI_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import AG_NEWS\n",
        "\n",
        "train_ = AG_NEWS(split=\"train\")"
      ],
      "metadata": {
        "id": "V7p6LtyekseI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* データセットは以下のように特殊な型を持つが・・・"
      ],
      "metadata": {
        "id": "nSia66JXjBfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE-D3-TXi-WP",
        "outputId": "ed9b49dc-59e2-4b10-cb69-e7d70186363d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* iter関数でiteratorに変換できる。\n",
        " * ちょっとデータセットの中身を見てみたい時は、こうすると便利。"
      ],
      "metadata": {
        "id": "rnDn9G9BqO69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = iter(train_)\n",
        "next(train_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHqblxiDpSTE",
        "outputId": "bca18ea7-9dc4-466a-b6b4-8cf727864927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0TqKtZfpU2a",
        "outputId": "5c208d19-7fd6-4764-84bc-4b811fca1610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt5ojbsoqN7Z",
        "outputId": "0ecc1126-05f4-4a59-badb-77d6aa3f0590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 前処理"
      ],
      "metadata": {
        "id": "cDcs6sxBqWLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 語彙集合の作成\n",
        " * 語彙を確定させるときは、訓練データだけを使うこと。\n",
        " * `build_vocab_from_iterator`についてはドキュメントを参照。\n",
        "  * https://pytorch.org/text/stable/vocab.html#build-vocab-from-iterator"
      ],
      "metadata": {
        "id": "FHvp9qjMqZDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# トークナイザを準備する\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# トークン化をおこなう関数\n",
        "def yield_tokens(data_):\n",
        "  for _, text in data_:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "# 訓練データをもとに語彙集合を作成（ほんの少し時間がかかる）\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "wJtJjpC4qRyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HugHDvHv3mjt",
        "outputId": "3bc6d85e-7250-4468-acab-5000d44f311e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchtext.vocab.vocab.Vocab"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 単語トークンの列が整数の列に変換されることを確認する。"
      ],
      "metadata": {
        "id": "KwPfiU3Xq8qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['here', 'is', 'an', 'example'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JxplX7Eq5kj",
        "outputId": "00ccbc8d-d370-4bed-e0fb-8bb3ce730bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 30, 5297]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oivhonJfyOqE",
        "outputId": "6fb743cd-d091-4781-c0c4-f00f4a6903d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95811"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 前処理のパイプラインの定義\n",
        " * テキストは、トークン化し、そして、idの列に変換する。\n",
        " * クラスラベルは、整数化し、1を引くことで値が0から始まるようにする。"
      ],
      "metadata": {
        "id": "-QWSHq16rQXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "metadata": {
        "id": "8zH0RUmIrHJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline('Here is an example.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXPLY4vkrVRZ",
        "outputId": "0a389b0f-0a20-4d98-c4d2-0f2b33ea921d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[475, 21, 30, 5297, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline('10')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rOPPs2VrbR4",
        "outputId": "faf97bfe-ff78-424e-aac7-9c1ac74c1943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collate関数\n",
        "* サンプルに前処理を施してミニバッチを作ることを、collateする、と言う。\n",
        "* collate関数の中で、先ほど定義した前処理パイプラインを呼び出している。\n",
        "* 今回は、同じミニバッチに含まれるテキストをすべてつなげてしまう。\n",
        "* `offsets`は各テキストが何トークン目から始まるかを表す。\n",
        "* このcollate関数は、後でDataLoaderを作るときに使う。"
      ],
      "metadata": {
        "id": "QUaiRtBo4VKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "  label_list, text_list, offsets = [], [], [0]\n",
        "  for _label, _text in batch:\n",
        "    label_list.append(label_pipeline(_label))\n",
        "    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    offsets.append(processed_text.size(0))\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  text_list = torch.cat(text_list)\n",
        "  return label_list.to(device), text_list.to(device), offsets.to(device)"
      ],
      "metadata": {
        "id": "NRrfbx4W4T2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "60xaGMzv3_XW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 訓練データとテストデータを用意する。"
      ],
      "metadata": {
        "id": "VksLnjK7mI3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ = AG_NEWS(split=\"train\")\n",
        "test_ = AG_NEWS(split=\"test\")"
      ],
      "metadata": {
        "id": "8VOjHeJ4mIYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 上のセルでやったことは、実は1行で以下のように書ける。"
      ],
      "metadata": {
        "id": "Davpg5t5mMwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_, test_ = AG_NEWS()"
      ],
      "metadata": {
        "id": "brJgjUGxmQ7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dataset型に変換する。\n",
        " * torchtextに用意されている`to_map_style_dataset`関数を使う。"
      ],
      "metadata": {
        "id": "MFDFGNVpmcbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_)\n",
        "test_dataset = to_map_style_dataset(test_)"
      ],
      "metadata": {
        "id": "jmrkLGGbmW9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 訓練データを２分割して検証データを作成する。"
      ],
      "metadata": {
        "id": "XyhyJZUFmooN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "# 訓練データから5%を取って検証データとする。\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")"
      ],
      "metadata": {
        "id": "JHBgz6gnmuYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader\n",
        "* 訓練データ、検証データ、テストデータのDataLoaderを作る。\n",
        "* collate関数の使い方に注目。"
      ],
      "metadata": {
        "id": "HiPXZZyim7Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ミニバッチのサイズを適当に決める\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "RQ-6jH0h4E-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル"
      ],
      "metadata": {
        "id": "VFuDSuMR52hU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `nn.EmbeddingBag`\n",
        "* 全トークンのembeddingの平均（または和）を一挙に求めるlayer。"
      ],
      "metadata": {
        "id": "LP6WNSYVeUfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "embedding = nn.EmbeddingBag(len(vocab), 8, sparse=False)"
      ],
      "metadata": {
        "id": "BtrYIvX0eS3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 本当に平均を求めているかを確認する。"
      ],
      "metadata": {
        "id": "0BVikXBriB_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"language models\"\n",
        "input = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
        "offsets = torch.tensor([0], dtype=torch.int64)\n",
        "embedding(input=input, offsets=offsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpdkpArLeqj-",
        "outputId": "b9098469-93e4-44f5-c146-0fbc915bab53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3720,  0.9064, -1.4657, -0.1584,  0.1959,  1.2021, -0.5094, -0.0792]],\n",
              "       grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"language\"\n",
        "input = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
        "offsets = torch.tensor([0], dtype=torch.int64)\n",
        "output1 = embedding(input=input, offsets=offsets)\n",
        "output1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_3fX1GCg_73",
        "outputId": "ae4019fa-4b0c-4f3d-a3a5-9b43e8959cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9283,  0.8008, -1.3259,  1.5126,  0.5105,  1.4376, -0.3588, -0.2826]],\n",
              "       grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"models\"\n",
        "input = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
        "offsets = torch.tensor([0], dtype=torch.int64)\n",
        "output2 = embedding(input=input, offsets=offsets)\n",
        "output2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnTSVqsPhCEW",
        "outputId": "725e97a6-e3e6-44ff-8271-f0318c16a62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1843,  1.0119, -1.6056, -1.8294, -0.1188,  0.9665, -0.6600,  0.1241]],\n",
              "       grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(output1 + output2) / 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5mc0lLghNOm",
        "outputId": "446a71a3-0ec0-44f3-84ae-70d498bc4dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3720,  0.9064, -1.4657, -0.1584,  0.1959,  1.2021, -0.5094, -0.0792]],\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* offsetはテキストの切れ目を表す。\n",
        "* 複数のテキストをつなげたままベクトル化できる。\n",
        " * メモリの効率も時間的な効率も良い。"
      ],
      "metadata": {
        "id": "9Ig_SXomh8oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"language models text classification\"\n",
        "input = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
        "offsets = torch.tensor([0, 2], dtype=torch.int64)\n",
        "embedding(input=input, offsets=offsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGHLsNTWh0mQ",
        "outputId": "548e99da-708c-4039-da3e-f025f6f5b985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3720,  0.9064, -1.4657, -0.1584,  0.1959,  1.2021, -0.5094, -0.0792],\n",
              "        [ 0.2176, -0.3015,  0.2869,  0.4253, -0.2544,  0.1135, -0.3574,  1.1874]],\n",
              "       grad_fn=<EmbeddingBagBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 分類モデル\n",
        "* `nn.Module`を継承して自前のクラスを定義する。\n"
      ],
      "metadata": {
        "id": "hFnexLcZ6Pkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, num_class):\n",
        "    super(TextClassificationModel, self).__init__()\n",
        "    # 埋め込み層\n",
        "    self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "    # 分類用の全結合層\n",
        "    self.fc = nn.Linear(embed_dim, num_class)\n",
        "    # 自前の重み初期化関数を呼び出す\n",
        "    self.init_weights()\n",
        "\n",
        "  # 自前の重み初期化関数\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.bias.data.zero_()\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self, text, offsets):\n",
        "    embedded = self.embedding(text, offsets)\n",
        "    return self.fc(embedded)"
      ],
      "metadata": {
        "id": "pRJysWR_r9cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 訓練データを使ってクラスの個数を調べる。"
      ],
      "metadata": {
        "id": "dtVoatKc7vBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = AG_NEWS(split=\"train\")\n",
        "num_class = len(set([label for (label, text) in train_iter]))"
      ],
      "metadata": {
        "id": "x4kpm5Ie7tMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 重要な定数を変数にセットする。"
      ],
      "metadata": {
        "id": "1u1m1i7e748S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 語彙サイズ\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 埋め込みベクトルの次元\n",
        "emsize = 64"
      ],
      "metadata": {
        "id": "UcPLpHkXsAag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* モデルのインスタンスを作成しGPUへ送る。\n",
        " * 上で値をセットした変数を使って初期化している。"
      ],
      "metadata": {
        "id": "q2UFwoEW71LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "metadata": {
        "id": "0BXZ2xKg7zJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 訓練に使うヘルパ関数"
      ],
      "metadata": {
        "id": "xxK-Sx4A7eFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0, 0\n",
        "  log_interval = 500\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    predicted_label = model(text, offsets)\n",
        "    loss = criterion(predicted_label, label)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "    optimizer.step()\n",
        "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "    total_count += label.size(0)\n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "      elapsed = time.time() - start_time\n",
        "      print(\n",
        "          \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
        "          \"| accuracy {:8.3f}\".format(\n",
        "              epoch, idx, len(dataloader), total_acc / total_count\n",
        "          )\n",
        "      )\n",
        "      total_acc, total_count = 0, 0\n",
        "      start_time = time.time()"
      ],
      "metadata": {
        "id": "BeGMjdPd7dXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 評価に使うヘルパ関数"
      ],
      "metadata": {
        "id": "aa0nVABe8GGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "      predicted_label = model(text, offsets)\n",
        "      loss = criterion(predicted_label, label)\n",
        "      total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "  return total_acc / total_count"
      ],
      "metadata": {
        "id": "8JEgh9O3sAPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習のハイパーパラメータ"
      ],
      "metadata": {
        "id": "iPLsWoz88SrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10  # epoch\n",
        "LR = 5  # learning rate"
      ],
      "metadata": {
        "id": "TJ8vB0_t8bAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "\n",
        "total_accu = None\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  epoch_start_time = time.time()\n",
        "  train(train_dataloader)\n",
        "  accu_val = evaluate(valid_dataloader)\n",
        "  if total_accu is not None and total_accu > accu_val:\n",
        "    scheduler.step()\n",
        "  else:\n",
        "    total_accu = accu_val\n",
        "  print(\"-\" * 59)\n",
        "  print(\n",
        "      \"| end of epoch {:3d} | time: {:5.2f}s | \"\n",
        "      \"valid accuracy {:8.3f} \".format(\n",
        "          epoch, time.time() - epoch_start_time, accu_val\n",
        "      )\n",
        "  )\n",
        "  print(\"-\" * 59)"
      ],
      "metadata": {
        "id": "vixuo6u2r__K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking the results of test dataset.\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(\"test accuracy {:8.3f}\".format(accu_test))"
      ],
      "metadata": {
        "id": "o45KtyPZsF68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
        "\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "  with torch.no_grad():\n",
        "    text = torch.tensor(text_pipeline(text))\n",
        "    output = model(text, torch.tensor([0]))\n",
        "    return output.argmax(1).item() + 1\n",
        "\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" % ag_news_label[predict(ex_text_str, text_pipeline)])"
      ],
      "metadata": {
        "id": "8FMoLIJ5sF3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUzVkJ2v-tt_"
      },
      "source": [
        "# 本日の課題\n",
        "* モデルやoptimizerやschedulerを変更して、validation setを使ってチューニングしよう。\n",
        "* 最後に、自分で選択した設定を使って、test set上で評価しよう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26RYXnmnbbSc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}