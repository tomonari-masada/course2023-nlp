{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Hz9rXJHZDZeEY4pbWkLYFhZftVekADdY",
      "authorship_tag": "ABX9TyMXahl3AzLK1jtoIcT5WCJa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2023-nlp/blob/main/04_word_vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t-iVvqcVnB5"
      },
      "source": [
        "# 単語ベクトル\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 今日のお題\n",
        "* 単語ベクトルを利用して、テキストをベクトル化する。\n",
        "* ベクトル化を埋め込み(embedding)と呼ぶ。\n",
        "  * 以下、埋め込みという言い方を使う。\n",
        "* こうして作ったベクトルを使って、テキスト分類問題を解く。\n",
        "* 同じ分類問題を、BERTでテキストをembedすることによって解く。\n",
        "* 両者の性能を比較する。"
      ],
      "metadata": {
        "id": "_-EtNb77zV-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 単語ベクトルとは\n",
        "* いわゆるword2vec。\n",
        "  * https://arxiv.org/abs/1301.3781\n",
        "  * https://en.wikipedia.org/wiki/Word2vec\n",
        "* 単語をベクトルとして表現したもの。\n",
        "  * 単語埋め込み、単語分散表現、などとも言われる。\n",
        "* 意味が近い単語はベクトルとしても近くなるように、作成されている。\n"
      ],
      "metadata": {
        "id": "WfOPYIogzO5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 単語ベクトルを作るアルゴリズム\n",
        "* アルゴリズム自体の説明は、この授業では割愛します。\n",
        "  * https://www.tensorflow.org/text/tutorials/word2vec\n",
        "* 大雑把には・・・\n",
        "  * テキストをたくさん集める。それらのテキストの中で・・・\n",
        "  * 各単語について、前後にどのような単語が出現するか、調べる。\n",
        "  * 前後に似たような単語が出現する単語は、似たようなベクトルにマッピングする。"
      ],
      "metadata": {
        "id": "pJf_QZP6r-8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 単語ベクトルの使いみち"
      ],
      "metadata": {
        "id": "7i5nod9rraEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 単語の類似度評価\n",
        "* ベクトルどうしの遠い近いを表す尺度は何でも使える。\n",
        "* 内積やコサイン類似度が使われることが多い。\n"
      ],
      "metadata": {
        "id": "IE7l-ut8CjdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テキスト埋め込み\n",
        "* 最もシンプルには、テキストに含まれるトークンの単語ベクトルの平均を取ればよい。\n",
        "  * これをmean poolingと呼ぶ。\n",
        "* 単語ベクトルを使ってテキストを埋め込むことは、最近は行わない。\n",
        "  * テキストのembedには、今は、深層学習言語モデルを使う。\n",
        "  * 今回はsentence BERTを使った方法を紹介する。"
      ],
      "metadata": {
        "id": "q9N1r-DYCFJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備"
      ],
      "metadata": {
        "id": "BAWlTIYQ_m2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 環境設定\n",
        "* 今回はランタイムのタイプでGPUを選んでおいてください。\n",
        "  * あとでBERTによるテキスト埋め込みと比較するため。"
      ],
      "metadata": {
        "id": "aFa_gCwe-9MF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 必要なライブラリのインストール"
      ],
      "metadata": {
        "id": "d07eAYNeyrMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "9JjurXjctOMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット"
      ],
      "metadata": {
        "id": "0MhVTD6Uy3Jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WRIME: 主観と客観の感情分析データセット\n",
        "* 詳細は、以下を参照。\n",
        "  * https://github.com/ids-cv/wrime\n",
        "* 短いテキストがたくさん含まれている。\n",
        "* -2, -1, 0, 1, 2の５段階でnegativeからpositiveの感情ラベルが付与されている。\n",
        "* 今回は、Hugging Face Hubからこのデータセットを取得する。\n"
      ],
      "metadata": {
        "id": "qrBMTq28uDNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"shunk031/wrime\", \"ver2\")"
      ],
      "metadata": {
        "id": "ex4ADCbhtGOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* はじめから、train, validation, testの3つの集合に分けられている。"
      ],
      "metadata": {
        "id": "Q3F06BjLAqTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "tags = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "texts = {}\n",
        "labels = {}\n",
        "for tag in tags:\n",
        "  texts[tag] = dataset[tag][\"sentence\"]\n",
        "  labels[tag] = [item[\"sentiment\"] for item in dataset[tag][\"avg_readers\"]]\n",
        "  labels[tag] = np.array(labels[tag])"
      ],
      "metadata": {
        "id": "cZNSO3N8uExN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[\"train\"][0]"
      ],
      "metadata": {
        "id": "5yqWB1Xv0vRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[\"train\"][0]"
      ],
      "metadata": {
        "id": "XsMEnwSv0yHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3F0XNxABxH_"
      },
      "source": [
        "## 単語ベクトルによるテキストの埋め込み\n",
        "* 小規模のモデル（名前が__`_sm`__で終わるモデル）は単語ベクトルを含まない。\n",
        "* 大規模モデルはダウンロードに時間がかかる。\n",
        "* そのため、中規模モデルをインストールする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4qKeUfdCDNu"
      },
      "source": [
        "### 日本語中規模モデルのインストール\n",
        "* https://spacy.io/models/ja#ja_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ja_core_news_md"
      ],
      "metadata": {
        "id": "-4jI7POINHwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テキストの埋め込み\n",
        "* spaCyではテキストを直接embedできる。\n",
        "  * 内部では単語ベクトルの平均を求めている。\n",
        "* （おそらく6分ぐらいかかります。）"
      ],
      "metadata": {
        "id": "s1Qsw6KFyCel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('ja_core_news_md')\n",
        "\n",
        "X = {}\n",
        "for tag in tags:\n",
        "  X[tag] = []\n",
        "  for text in tqdm(texts[tag]):\n",
        "    tokens = nlp(text)\n",
        "    X[tag].append(tokens.vector)\n",
        "  X[tag] = np.array(X[tag])"
      ],
      "metadata": {
        "id": "uTeYy91XwEsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"train\"].shape"
      ],
      "metadata": {
        "id": "5R22Zu7bxxs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* embedした結果とラベルを保存しておく。"
      ],
      "metadata": {
        "id": "m5-qau2lB_xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tag in tags:\n",
        "  with open(f'wrime_{tag}_vec.npy', 'wb') as f:\n",
        "    np.save(f, X[tag])\n",
        "  with open(f'wrime_{tag}_label.npy', 'wb') as f:\n",
        "    np.save(f, labels[tag])"
      ],
      "metadata": {
        "id": "fWNSFVz4yZrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ラベルの前処理"
      ],
      "metadata": {
        "id": "Hi6OckWd3OkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 保存しておいたテキストのベクトル表現とラベルを読み込む。"
      ],
      "metadata": {
        "id": "MLHWsnKbAS0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "tags = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "X = {}\n",
        "labels = {}\n",
        "for tag in tags:\n",
        "  with open(f'wrime_{tag}_vec.npy', 'rb') as f:\n",
        "    X[tag] = np.load(f)\n",
        "  with open(f'wrime_{tag}_label.npy', 'rb') as f:\n",
        "    labels[tag] = np.load(f)"
      ],
      "metadata": {
        "id": "ymyGRShtzMxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"train\"].shape"
      ],
      "metadata": {
        "id": "0rZG7F6R1oan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[\"train\"].shape"
      ],
      "metadata": {
        "id": "EFtCpabq1rN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 今回は、データセットのラベルを2値に単純化する\n",
        "  * ラベル0のテキストは取り除く。\n",
        "  * negativeを示す-2と-1は、一つのクラスにまとめる。\n",
        "  * positiveを示す1と2も、一つのクラスにまとめる。"
      ],
      "metadata": {
        "id": "M3fPpNHdAXXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_binary = {}\n",
        "labels_binary = {}\n",
        "for tag in tags:\n",
        "  indices = labels[tag] != 0\n",
        "  X_binary[tag] = X[tag][indices]\n",
        "  labels_binary[tag] = labels[tag][indices]\n",
        "  labels_binary[tag] = (labels_binary[tag] > 0) * 1"
      ],
      "metadata": {
        "id": "sjKnS5zl2Zqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EIlDmklyYaP"
      },
      "source": [
        "### 文書分類"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 適宜、チューニングしてください。\n",
        "* 分類手法は`LinearSVC`でなくても構いません。"
      ],
      "metadata": {
        "id": "7dyTKwyz3XLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "cls = LinearSVC()\n",
        "cls.fit(X_binary[\"train\"], labels_binary[\"train\"])\n",
        "cls.score(X_binary[\"validation\"], labels_binary[\"validation\"])"
      ],
      "metadata": {
        "id": "YMbe-h8d1uYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im8djYmZkB3b"
      },
      "source": [
        "## BERTによるテキストの埋め込み\n",
        "* BERTにはいろいろな種類がある。\n",
        "* 今日は、sentence BERTと呼ばれるBERTを使う。\n",
        "* sentence BERTの説明は、今日はしない。とりあえず使う。\n",
        "  * 単にテキストをembedするツールとして使う。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 必要なライブラリのインストール"
      ],
      "metadata": {
        "id": "AfX3eDm2BmAY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6V_dyqv0n1o"
      },
      "source": [
        "!pip install -q transformers fugashi[unidic-lite]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "dLFNjOLq5SEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sentence BERTのロード\n",
        "* 初回だけダウンロードに時間がかかる。\n",
        "* 2回目以降は、ローカルに保存したモデルをロードするだけ。"
      ],
      "metadata": {
        "id": "I3RGWUNzBoo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedder = SentenceTransformer(\"cl-tohoku/bert-base-japanese-v3\")"
      ],
      "metadata": {
        "id": "P1yDjdhl4rid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テキストの埋め込み\n",
        "* 内部では、BERTの出力のmean pooling\n",
        "  * 詳細は、今日のところは、割愛します。"
      ],
      "metadata": {
        "id": "6cRGusJkB32F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* （おそらく2分ぐらいで終わります。）"
      ],
      "metadata": {
        "id": "zR1WmXqr4Nox"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LalaUJ22k9dU"
      },
      "source": [
        "X = {}\n",
        "for tag in tags:\n",
        "  X[tag] = embedder.encode(texts[tag])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* embedした結果を保存しておく。"
      ],
      "metadata": {
        "id": "kHCop4-NB6aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for tag in tags:\n",
        "  with open(f'wrime_{tag}_bert_vec.npy', 'wb') as f:\n",
        "    np.save(f, X[tag])"
      ],
      "metadata": {
        "id": "Zt1V4CIY9ASi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文書分類"
      ],
      "metadata": {
        "id": "2czjVRjK43HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "tags = [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "X = {}\n",
        "labels = {}\n",
        "for tag in tags:\n",
        "  with open(f'wrime_{tag}_bert_vec.npy', 'rb') as f:\n",
        "    X[tag] = np.load(f)\n",
        "  with open(f'wrime_{tag}_label.npy', 'rb') as f:\n",
        "    labels[tag] = np.load(f)"
      ],
      "metadata": {
        "id": "RYo9lR5k4fTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ラベルを2値に単純化する。先ほどと同じ。つまり・・・\n",
        "  * ラベル0のテキストは取り除く。\n",
        "  * negativeを示す-2と-1は、一つのクラスにまとめる。\n",
        "  * positiveを示す1と2も、一つのクラスにまとめる。"
      ],
      "metadata": {
        "id": "KZn8tgZHDLvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_binary = {}\n",
        "labels_binary = {}\n",
        "for tag in tags:\n",
        "  indices = labels[tag] != 0\n",
        "  X_binary[tag] = X[tag][indices]\n",
        "  labels_binary[tag] = labels[tag][indices]\n",
        "  labels_binary[tag] = (labels_binary[tag] > 0) * 1"
      ],
      "metadata": {
        "id": "xOzoTpnJ6AHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 適宜、チューニングしてください。\n",
        "* 分類手法は`LinearSVC`でなくても構いません。"
      ],
      "metadata": {
        "id": "NgmhXoBA6dpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "cls = LinearSVC()\n",
        "cls.fit(X_binary[\"train\"], labels_binary[\"train\"])\n",
        "cls.score(X_binary[\"validation\"], labels_binary[\"validation\"])"
      ],
      "metadata": {
        "id": "-tPqsl069Upi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss1gBFpoATIR"
      },
      "source": [
        "# 本日の課題\n",
        "* 上で実行した感情分析の性能を上げてください。\n",
        "* チューニングが済んだら、テストセットでscoreを計算してください。\n",
        "  * 別の評価尺度で評価してもらっても構いません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnK61odfnND7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}