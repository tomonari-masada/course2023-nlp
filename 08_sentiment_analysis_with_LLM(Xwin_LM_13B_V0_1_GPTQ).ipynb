{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmAb4+gCUl6JNaogoLOUYC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a0a35b5028349f0a96d64e7eb7c8911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32486d0891d34f4eb5d8e12738025edb",
              "IPY_MODEL_3aa0161260474323b4144e86d4891731",
              "IPY_MODEL_f053478196eb4d1fa2c32b158f97ff2a"
            ],
            "layout": "IPY_MODEL_0c3713fd30ab4444b7b308fdb46e6ca9"
          }
        },
        "32486d0891d34f4eb5d8e12738025edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20932a1526ed46628ed5e2b8348c117f",
            "placeholder": "​",
            "style": "IPY_MODEL_f85da28ff860440bad2e4b9ed63d7a09",
            "value": "Downloading (…)quantize_config.json: 100%"
          }
        },
        "3aa0161260474323b4144e86d4891731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_712e99a0399047739b98dedbeaabf39c",
            "max": 186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_185a0bd837ea47808e50f420d3a19037",
            "value": 186
          }
        },
        "f053478196eb4d1fa2c32b158f97ff2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ef00590f3f4919bf0a4d5ebbd3db52",
            "placeholder": "​",
            "style": "IPY_MODEL_b72934892bb84860896bcc2ef785a8fa",
            "value": " 186/186 [00:00&lt;00:00, 3.70kB/s]"
          }
        },
        "0c3713fd30ab4444b7b308fdb46e6ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20932a1526ed46628ed5e2b8348c117f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85da28ff860440bad2e4b9ed63d7a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "712e99a0399047739b98dedbeaabf39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185a0bd837ea47808e50f420d3a19037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7ef00590f3f4919bf0a4d5ebbd3db52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72934892bb84860896bcc2ef785a8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0429c4ca5d2438f8de720a6f406a5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1998b39c493451e92d81f4ae048a442",
              "IPY_MODEL_137b3be348fe47469889de2addb44e2b",
              "IPY_MODEL_f449cbaebef74ff49b56349bade5e250"
            ],
            "layout": "IPY_MODEL_7abc8f8dc5774b2fa70e74a5c54d11bd"
          }
        },
        "b1998b39c493451e92d81f4ae048a442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c735a92a5a4a7792bdc3001f3c4c38",
            "placeholder": "​",
            "style": "IPY_MODEL_292693b4028e4f54905a57e3357018f0",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "137b3be348fe47469889de2addb44e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dda6183867f0425393538e7647550356",
            "max": 7259435192,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bff6c1f43714aa69a72c66e854827fc",
            "value": 7259435192
          }
        },
        "f449cbaebef74ff49b56349bade5e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffacdf9876f94ba9b0dda975af620e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_c3c0c5dba5ac432280e40779b206c077",
            "value": " 7.26G/7.26G [00:44&lt;00:00, 250MB/s]"
          }
        },
        "7abc8f8dc5774b2fa70e74a5c54d11bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c735a92a5a4a7792bdc3001f3c4c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292693b4028e4f54905a57e3357018f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dda6183867f0425393538e7647550356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bff6c1f43714aa69a72c66e854827fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffacdf9876f94ba9b0dda975af620e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c0c5dba5ac432280e40779b206c077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1301a904cf54030a1146989596013a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_604d5ba0f0104f51a9d965f91397c3f5",
              "IPY_MODEL_325201157a8240dda49b76e23fd98e1e",
              "IPY_MODEL_a53f4da8c69b47fd98f0d535a72bd7c6"
            ],
            "layout": "IPY_MODEL_d0e1f364cccb4f38920947a3eb1e8e7a"
          }
        },
        "604d5ba0f0104f51a9d965f91397c3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d482aa92304e16bda33edc07c44ba7",
            "placeholder": "​",
            "style": "IPY_MODEL_b5adb0b5e72043188fdb1758d48502c9",
            "value": "Map: 100%"
          }
        },
        "325201157a8240dda49b76e23fd98e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_308806a123cd448195ae59ed01dc70aa",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13c4bbef91fb4ec1942253a2820bd803",
            "value": 2500
          }
        },
        "a53f4da8c69b47fd98f0d535a72bd7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c2b9f34e1444b538215d82f33ece88a",
            "placeholder": "​",
            "style": "IPY_MODEL_323e143514534a27b411b28af63a1a89",
            "value": " 2500/2500 [00:00&lt;00:00, 4401.82 examples/s]"
          }
        },
        "d0e1f364cccb4f38920947a3eb1e8e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d482aa92304e16bda33edc07c44ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5adb0b5e72043188fdb1758d48502c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "308806a123cd448195ae59ed01dc70aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c4bbef91fb4ec1942253a2820bd803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c2b9f34e1444b538215d82f33ece88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "323e143514534a27b411b28af63a1a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2023-nlp/blob/main/08_sentiment_analysis_with_LLM(Xwin_LM_13B_V0_1_GPTQ).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLMを使ってみる\n",
        "* 今日は、とりあえず、LLMを使ってみる。"
      ],
      "metadata": {
        "id": "s7UHVLvsl89T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 今日の授業の目的\n",
        "* いまどのくらい手軽にLLMを使えるようになっているかを、とりあえず体感する。\n",
        "* 技術的な詳細は次回以降学んでいくことにして、とにかく使ってみる。"
      ],
      "metadata": {
        "id": "7HPNt4EWmD-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **ランタイムのタイプをGPUに設定しておくこと。**"
      ],
      "metadata": {
        "id": "R0tqelrXmhun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 例題: LLMによる感情分析(sentiment analysis)\n",
        "* 今日は、WRIMEというデータセットを使って、LLMに感情分析させてみる。\n",
        "* 感情分析とは、テキストが表す感情を分析するタスク。\n",
        " * ポジティブな感情か、ネガティブな感情かの2値分類タスクとして解くことが多い。\n",
        " * 今日は、ニュートラルな感情も含めた3値分類問題として解くことにする。\n",
        "* LLMとしてはXwin-LM-13B-V0.1を使う。\n",
        " * プロンプトを使ったテキスト生成によって感情分析の問題を解く。"
      ],
      "metadata": {
        "id": "7PtjYmygnqm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備\n",
        "* Hugging Faceの各種ライブラリを使えば、簡単なコードを書くだけでLLMを使える。"
      ],
      "metadata": {
        "id": "3GIHAP_Rrgkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformersライブラリのインストール\n",
        "* https://huggingface.co/docs/transformers/index"
      ],
      "metadata": {
        "id": "3FEPliNumzPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "2W5-9kWlm1qS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e60cdf-25c6-4ebb-89af-2bcf313db386"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasetsライブラリのインストール\n",
        "* https://huggingface.co/docs/datasets/index"
      ],
      "metadata": {
        "id": "eGHG8EeTnPQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "OXa6Thx-nGVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d845acf0-6d03-4c80-dc76-7d02029e7d77"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.14.5 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accelerateライブラリのインストール\n",
        "* https://huggingface.co/docs/accelerate/index"
      ],
      "metadata": {
        "id": "aJKj8VXHrauA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "GCTSWrIsrWaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0a4f6c-4441-4ec9-aa92-8aa999dcb01f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/258.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m194.6/258.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 量子化されたモデルを使うためのライブラリAutoGPTQのインストール\n",
        "* https://huggingface.co/docs/optimum/llm_quantization/usage_guides/quantization\n",
        " * https://huggingface.co/blog/gptq-integration"
      ],
      "metadata": {
        "id": "wORDq1mJ07Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-gptq"
      ],
      "metadata": {
        "id": "sHQ6_PlWxQf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb291ba-8e17-4872-973b-3fc34a4a9e3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting auto-gptq\n",
            "  Downloading auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.23.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.14.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Collecting rouge (from auto-gptq)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.0.1+cu118)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.3.3)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.33.2)\n",
            "Collecting peft (from auto-gptq)\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (0.17.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
            "Installing collected packages: rouge, peft, auto-gptq\n",
            "Successfully installed auto-gptq-0.4.2 peft-0.5.0 rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ここでランタイムを再起動する。**"
      ],
      "metadata": {
        "id": "ntPSyIO8r83H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### インポート"
      ],
      "metadata": {
        "id": "eX6zotwEoK2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "9A6Euk7gmXNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3c7231-819a-4495-bb0a-c5789b6abe68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7caf2329bf30>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット\n",
        "* Ver. 2 の方を使う。\n",
        " * WRIME: 主観と客観の感情分析データセット https://github.com/ids-cv/wrime\n",
        "* Hugging Faceのdatasets hubに登録されているので、簡単に扱うことができる。"
      ],
      "metadata": {
        "id": "ELjoQ6q_oTAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WRIMEデータセットの取得\n",
        "* training 30,000件、validation 2,500件、test 2,500件。\n",
        "* 最初だけ、ダウンロードに時間がかかる。"
      ],
      "metadata": {
        "id": "oC5RDmUWosMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"shunk031/wrime\", \"ver2\")"
      ],
      "metadata": {
        "id": "4A0Qp1JsoRaE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "julWQgfCox2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10aca9ac-966d-4343-d0d5-1725d057a228"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'user_id', 'datetime', 'writer', 'reader1', 'reader2', 'reader3', 'avg_readers'],\n",
              "        num_rows: 30000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'user_id', 'datetime', 'writer', 'reader1', 'reader2', 'reader3', 'avg_readers'],\n",
              "        num_rows: 2500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'user_id', 'datetime', 'writer', 'reader1', 'reader2', 'reader3', 'avg_readers'],\n",
              "        num_rows: 2500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"validation\"][0]"
      ],
      "metadata": {
        "id": "f6ssdeeOo7kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88ab732-9bb7-496d-8848-410d9e264b97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': '建設中の建物の利用目的も変更になるだろうなあ。',\n",
              " 'user_id': '26',\n",
              " 'datetime': '2020/5/10 10:59',\n",
              " 'writer': {'joy': 0,\n",
              "  'sadness': 3,\n",
              "  'anticipation': 1,\n",
              "  'surprise': 3,\n",
              "  'anger': 0,\n",
              "  'fear': 3,\n",
              "  'disgust': 0,\n",
              "  'trust': 0,\n",
              "  'sentiment': 0},\n",
              " 'reader1': {'joy': 0,\n",
              "  'sadness': 0,\n",
              "  'anticipation': 0,\n",
              "  'surprise': 0,\n",
              "  'anger': 0,\n",
              "  'fear': 0,\n",
              "  'disgust': 2,\n",
              "  'trust': 0,\n",
              "  'sentiment': 0},\n",
              " 'reader2': {'joy': 0,\n",
              "  'sadness': 1,\n",
              "  'anticipation': 1,\n",
              "  'surprise': 0,\n",
              "  'anger': 0,\n",
              "  'fear': 0,\n",
              "  'disgust': 0,\n",
              "  'trust': 0,\n",
              "  'sentiment': 0},\n",
              " 'reader3': {'joy': 0,\n",
              "  'sadness': 0,\n",
              "  'anticipation': 0,\n",
              "  'surprise': 0,\n",
              "  'anger': 0,\n",
              "  'fear': 2,\n",
              "  'disgust': 0,\n",
              "  'trust': 0,\n",
              "  'sentiment': -1},\n",
              " 'avg_readers': {'joy': 0,\n",
              "  'sadness': 0,\n",
              "  'anticipation': 0,\n",
              "  'surprise': 0,\n",
              "  'anger': 0,\n",
              "  'fear': 1,\n",
              "  'disgust': 1,\n",
              "  'trust': 0,\n",
              "  'sentiment': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 正解ラベルの確認"
      ],
      "metadata": {
        "id": "h4lUC6lprDdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 今回は、`avg_readers`の`sentiment`を正解ラベルとして使用する。"
      ],
      "metadata": {
        "id": "V-uvFcwepEzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "labels = []\n",
        "for example in dataset[\"validation\"]:\n",
        "  labels.append(example[\"avg_readers\"][\"sentiment\"])\n",
        "Counter(labels)"
      ],
      "metadata": {
        "id": "BMLNCNk_pLhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8cb08b-c124-46c1-a37c-175301b52b3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 892, -1: 715, 1: 764, -2: 69, 2: 60})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 元のデータでは５値。\n",
        "* 今回は、-2と-1をnegativeとして、2と1をpositiveとして、それぞれまとめることにする。\n",
        " * これで3値分類の問題になる。\n",
        " * このための前処理は後で行う。"
      ],
      "metadata": {
        "id": "sSlTKQelp3ZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM\n"
      ],
      "metadata": {
        "id": "ACC0ED27qZtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 今回は、Xwin-LM-13B-V0.1を使う。\n",
        " * https://huggingface.co/Xwin-LM/Xwin-LM-13B-V0.1\n",
        "* だが、Google Colab無料版では、この元のモデルは大きすぎて使えない・・・。\n",
        "* そこで、量子化された下記のモデルを代わりに使う。\n",
        " * https://huggingface.co/TheBloke/Xwin-LM-13B-V0.1-GPTQ"
      ],
      "metadata": {
        "id": "kIsSj4bzq7Cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xwin-LM-13B-V0.1-GPTQの取得\n",
        "* モデルのダウンロードに少し時間がかかる。\n",
        "* `AutoGPTQForCausalLM`クラスについては、以下を参照。\n",
        " * https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/modeling/auto.py"
      ],
      "metadata": {
        "id": "qVJVYtaKrGwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* safetensorsについては、以下を参照。\n",
        " * https://huggingface.co/docs/diffusers/using-diffusers/using_safetensors"
      ],
      "metadata": {
        "id": "sFvxES91acnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `trust_remote_code`については、[ここ](https://huggingface.co/docs/transformers/model_doc/auto)に以下のような説明がある。\n",
        "\n",
        "> Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to True for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.\n",
        "\n"
      ],
      "metadata": {
        "id": "4m_BJPRmbxSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "\n",
        "model_name = \"TheBloke/Xwin-LM-13B-V0.1-GPTQ\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "    model_name,\n",
        "    use_safetensors=True,\n",
        "    inject_fused_attention=False,\n",
        "    device=\"cuda:0\",\n",
        "    #trust_remote_code=True,\n",
        "    )\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "PYR1TtgLrGcv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            "8a0a35b5028349f0a96d64e7eb7c8911",
            "32486d0891d34f4eb5d8e12738025edb",
            "3aa0161260474323b4144e86d4891731",
            "f053478196eb4d1fa2c32b158f97ff2a",
            "0c3713fd30ab4444b7b308fdb46e6ca9",
            "20932a1526ed46628ed5e2b8348c117f",
            "f85da28ff860440bad2e4b9ed63d7a09",
            "712e99a0399047739b98dedbeaabf39c",
            "185a0bd837ea47808e50f420d3a19037",
            "b7ef00590f3f4919bf0a4d5ebbd3db52",
            "b72934892bb84860896bcc2ef785a8fa",
            "b0429c4ca5d2438f8de720a6f406a5b5",
            "b1998b39c493451e92d81f4ae048a442",
            "137b3be348fe47469889de2addb44e2b",
            "f449cbaebef74ff49b56349bade5e250",
            "7abc8f8dc5774b2fa70e74a5c54d11bd",
            "69c735a92a5a4a7792bdc3001f3c4c38",
            "292693b4028e4f54905a57e3357018f0",
            "dda6183867f0425393538e7647550356",
            "1bff6c1f43714aa69a72c66e854827fc",
            "ffacdf9876f94ba9b0dda975af620e8e",
            "c3c0c5dba5ac432280e40779b206c077"
          ]
        },
        "outputId": "9c7bbe6b-ef62-4ba6-b563-74fe5e10ee02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)quantize_config.json:   0%|          | 0.00/186 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a0a35b5028349f0a96d64e7eb7c8911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/7.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0429c4ca5d2438f8de720a6f406a5b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_gptq.nn_modules.fused_llama_mlp:skip module injection for FusedLlamaMLPForQuantizedModel not support integrate without triton yet.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaGPTQForCausalLM(\n",
              "  (model): LlamaForCausalLM(\n",
              "    (model): LlamaModel(\n",
              "      (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n",
              "      (layers): ModuleList(\n",
              "        (0-39): 40 x LlamaDecoderLayer(\n",
              "          (self_attn): LlamaAttention(\n",
              "            (rotary_emb): LlamaRotaryEmbedding()\n",
              "            (k_proj): GeneralQuantLinear(in_features=5120, out_features=5120, bias=True)\n",
              "            (o_proj): GeneralQuantLinear(in_features=5120, out_features=5120, bias=True)\n",
              "            (q_proj): GeneralQuantLinear(in_features=5120, out_features=5120, bias=True)\n",
              "            (v_proj): GeneralQuantLinear(in_features=5120, out_features=5120, bias=True)\n",
              "          )\n",
              "          (mlp): LlamaMLP(\n",
              "            (act_fn): SiLUActivation()\n",
              "            (down_proj): GeneralQuantLinear(in_features=13824, out_features=5120, bias=True)\n",
              "            (gate_proj): GeneralQuantLinear(in_features=5120, out_features=13824, bias=True)\n",
              "            (up_proj): GeneralQuantLinear(in_features=5120, out_features=13824, bias=True)\n",
              "          )\n",
              "          (input_layernorm): LlamaRMSNorm()\n",
              "          (post_attention_layernorm): LlamaRMSNorm()\n",
              "        )\n",
              "      )\n",
              "      (norm): LlamaRMSNorm()\n",
              "    )\n",
              "    (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## プロンプト\n",
        "* LLMがうまく感情分析をしてくれそうなプロンプトを考える。\n",
        " * 下はあくまで一つの例。"
      ],
      "metadata": {
        "id": "i5-ymVqjvFDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プロンプト作成用のヘルパ関数"
      ],
      "metadata": {
        "id": "c33BfNxjypMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_INST, E_INST = \"\", \"答え：\"\n",
        "B_SYS, E_SYS = \"\\n\", \"\\n\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\"\n",
        "\n",
        "def make_prompt(example):\n",
        "  sentence = example['sentence']\n",
        "  text = \"「\" + sentence + \"」と言っている人の気持ちは、どのように説明できますか。\"\n",
        "  text += \"また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。\"\n",
        "  text += \"どちらでもなければ、「どちらでもない」と答えてください。\"\n",
        "  prompt = \"{b_inst} {system}{prompt} {e_inst} \".format(\n",
        "      b_inst=B_INST,\n",
        "      system=f\"{B_SYS}{DEFAULT_SYSTEM_PROMPT}{E_SYS}\",\n",
        "      prompt=text,\n",
        "      e_inst=E_INST,\n",
        "      )\n",
        "  example['sentence'] = prompt\n",
        "  return example"
      ],
      "metadata": {
        "id": "Q7gEATn-y3RX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 元のテキストをプロンプトに一括変換する。"
      ],
      "metadata": {
        "id": "sU-cGHd2zRBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set = dataset[\"validation\"].map(make_prompt)"
      ],
      "metadata": {
        "id": "aJcIVmkjzPkz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_set[0][\"sentence\"])"
      ],
      "metadata": {
        "id": "aqp3lDmbzWJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d155fdd8-0e90-4d3c-a545-1acc1bc7e41f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「建設中の建物の利用目的も変更になるだろうなあ。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* プロンプトをあらかじめトークン化しておく。"
      ],
      "metadata": {
        "id": "kJ0e3l3lziue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set = validation_set.map(lambda samples: tokenizer(samples['sentence']), batched=True)"
      ],
      "metadata": {
        "id": "yYTlet7Gzn3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f1301a904cf54030a1146989596013a4",
            "604d5ba0f0104f51a9d965f91397c3f5",
            "325201157a8240dda49b76e23fd98e1e",
            "a53f4da8c69b47fd98f0d535a72bd7c6",
            "d0e1f364cccb4f38920947a3eb1e8e7a",
            "a4d482aa92304e16bda33edc07c44ba7",
            "b5adb0b5e72043188fdb1758d48502c9",
            "308806a123cd448195ae59ed01dc70aa",
            "13c4bbef91fb4ec1942253a2820bd803",
            "7c2b9f34e1444b538215d82f33ece88a",
            "323e143514534a27b411b28af63a1a89"
          ]
        },
        "outputId": "fc0a2656-ceaf-40de-db76-2f8be1d3a8a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1301a904cf54030a1146989596013a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `input_ids`というフィールドにトークン化の結果が格納されている。"
      ],
      "metadata": {
        "id": "GN_FVAqCz2Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_set[0][\"input_ids\"])"
      ],
      "metadata": {
        "id": "P-1YpzxwzsGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ceaf41-4863-4787-9e28-b33fd8d44569"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 259, 13, 30641, 30371, 30366, 30449, 235, 173, 163, 31525, 30499, 232, 135, 173, 31701, 30371, 30325, 30346, 30313, 30199, 30310, 30373, 30255, 30369, 30203, 30279, 30499, 30330, 30313, 30199, 233, 135, 162, 30993, 30396, 232, 178, 162, 30427, 30332, 30199, 30458, 31050, 31474, 30499, 30427, 30267, 13, 13, 13, 30481, 30886, 31770, 30275, 30199, 30886, 30834, 30199, 31107, 30406, 30895, 30210, 30723, 31786, 31100, 30353, 30371, 30332, 30955, 31206, 30465, 30371, 30641, 30267, 30482, 30364, 31243, 30665, 30466, 30298, 30332, 30313, 30199, 31648, 31695, 30644, 30449, 30330, 31250, 30199, 30787, 30465, 30353, 235, 173, 175, 30592, 30499, 30538, 30441, 30427, 30412, 30267, 30441, 30366, 30330, 31110, 30199, 31648, 31695, 30644, 30396, 31936, 232, 144, 155, 30968, 30499, 31243, 30465, 30364, 30330, 30936, 30199, 31250, 30644, 30513, 30499, 30427, 30412, 30383, 30481, 232, 175, 140, 30326, 30298, 30482, 30330, 30481, 233, 133, 181, 30326, 30298, 30482, 30267, 31250, 30644, 30513, 30499, 30723, 30371, 30807, 30553, 31254, 30330, 30481, 31250, 30644, 30513, 30499, 30723, 30371, 30298, 30482, 30364, 234, 176, 151, 30914, 30466, 30568, 30955, 30566, 30298, 30267, 29871, 234, 176, 151, 30914, 30383, 29871]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens([1])"
      ],
      "metadata": {
        "id": "gSCcZ88eY2hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3366b354-9586-4cae-f35b-70dee527c3a1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 感情分析"
      ],
      "metadata": {
        "id": "6PahFnk2z-lU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5値を3値に変換するヘルパ関数"
      ],
      "metadata": {
        "id": "wOpsD35O0C5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(example):\n",
        "  sentiment_dic = {-2:'悲しい', -1:'悲しい', 0:'どちらでもない', 1:'嬉しい', 2:'嬉しい'}\n",
        "  sentiment = example['avg_readers']['sentiment']\n",
        "  return sentiment_dic[sentiment]"
      ],
      "metadata": {
        "id": "vPpQGdxx0J0B"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 感情分析の実行"
      ],
      "metadata": {
        "id": "QRYi_49i1Gdt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KKPWp6jdW9fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a99109b-44f7-4e98-cbe8-14be53d1dd96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「建設中の建物の利用目的も変更になるだろうなあ。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「悲しい」\n",
            "ground truth:\t「どちらでもない」\n",
            "--------------------------------------------------------------------------------\n",
            "[2]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「演劇とかも同時並行でやっている。演劇の危機にどう思ってるか知りたかった。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「悲しい」\n",
            "ground truth:\t「どちらでもない」\n",
            "--------------------------------------------------------------------------------\n",
            "[3]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「犬夜叉には腐女子っていないのかな？というかあの漫画はＮＬ向けの漫画なのかも。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「嬉しい」\n",
            "ground truth:\t「どちらでもない」\n",
            "--------------------------------------------------------------------------------\n",
            "[4]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「話を続けるための子どもって感じかな。\n",
            "でも、それって簡単にやってはいけない気もする。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「悲しい」\n",
            "ground truth:\t「悲しい」\n",
            "--------------------------------------------------------------------------------\n",
            "[5]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「今、製作中の劇場版が子どもとかだったらどうしよう。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「嬉しい」\n",
            "ground truth:\t「悲しい」\n",
            "--------------------------------------------------------------------------------\n",
            "[6]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「終わってから勝手に子どもとかは今の時代に厳しいよねー\n",
            "銀魂だったらショック。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「悲しい」\n",
            "ground truth:\t「悲しい」\n",
            "--------------------------------------------------------------------------------\n",
            "[7]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「銀魂はあの終わり方は全ての界隈で大変、評価されていて、そういう意味での空知先生、ありがとう連呼だった。\n",
            "妄想の余地を残してくれてありがとう。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「悲しい」\n",
            "ground truth:\t「嬉しい」\n",
            "--------------------------------------------------------------------------------\n",
            "[8]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「ジャンプの休載、終わってるからもはや関係なくて・・・」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「悲しい」\n",
            "ground truth:\t「悲しい」\n",
            "--------------------------------------------------------------------------------\n",
            "[9]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「年末まで見合わせって驚く決断だと思う。\n",
            "それなら紅白もダメじゃない？」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「嬉しい」\n",
            "ground truth:\t「どちらでもない」\n",
            "--------------------------------------------------------------------------------\n",
            "[10]--------------------------------------------------------------------------------\n",
            " \n",
            "あなたは誠実で優秀な日本人のアシスタントで、人の感情を察するのが得意です。\n",
            "\n",
            "\n",
            "「こんな時だから？？\n",
            "知ってる人が何してるかが必要以上に気になるねー\n",
            "生存確認的な意味で。」と言っている人の気持ちは、どのように説明できますか。また、その気持ちを１単語で言うと、次のどちらですか：「嬉しい」、「悲しい」。どちらでもなければ、「どちらでもない」と答えてください。 答え： \n",
            "prediction:\t「悲しい」\n",
            "ground truth:\t「どちらでもない」\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  print(f'[{i+1}]' + '-'*80)\n",
        "  instance = validation_set[i]\n",
        "  prompt = instance[\"sentence\"]\n",
        "  with torch.no_grad():\n",
        "    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    output_ids = model.generate(\n",
        "        input_ids=token_ids.to(model.device),\n",
        "        max_new_tokens=256,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "  output = tokenizer.decode(output_ids.tolist()[0][token_ids.size(1) :], skip_special_tokens=True)\n",
        "  print(f\"{prompt}\\nprediction:\\t{output}\")\n",
        "  print(f\"ground truth:\\t「{get_sentiment(instance)}」\")\n",
        "  print('-'*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 本日の課題\n",
        "* もっとうまくLLMに感情分析をさせるプロンプトを考えてみよう。"
      ],
      "metadata": {
        "id": "-cXKf5dF0vRp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUXcB4axyCQO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}